# Q1
## How many c source are listed ?

there are 35 source in io_uring folder:
## advise.c
## alloc_chace.c
## cancel.c
## epol.c
## eventfd.c
## fdinfo.c
## filetable.c
## fs.c
## futex.c

## io-wq.c
Implements the core logic for the io_uring worker thread pool, including worker creation, scheduling, cancellation, and affinity management. Handles the queuing and execution of asynchronous work items, manages worker lifecycle, and enforces concurrency and hashing constraints for safe parallel execution. Provides mechanisms for worker wakeup, sleep, and exit, as well as cancellation of pending and running work.


## io_uring.c
Implements the main io_uring kernel interface, managing submission and completion rings, request lifecycle, and system call entry points. Handles initialization, teardown, memory management, request submission, completion event posting, and cancellation. Coordinates with worker threads, manages task context, and enforces synchronization and memory ordering between user and kernel space for efficient asynchronous I/O operations.


## kbuf.c
Implements management of provided buffers for io_uring operations, including buffer selection, registration, removal, and recycling. Handles both classic and ring-mapped buffer groups, supports dynamic buffer allocation, and ensures safe concurrent access and cleanup. Provides mechanisms for user-space buffer registration, buffer lookup, and integration with the io_uring submission and completion paths.


## memmap.c
Implements memory mapping and region management for io_uring, including allocation, pinning, and freeing of memory regions used for submission/completion rings and user-provided buffers. Handles both kernel and user memory, supports safe mapping/unmapping, and provides architecture-specific logic for MMU and no-MMU systems. Ensures proper accounting, validation, and cleanup of memory regions associated with io_uring contexts.


## msg_ring.c
Implements support for io_uring's MSG_RING operations, enabling message passing and file descriptor transfer between io_uring instances. Handles preparation, validation, and execution of MSG_RING commands, including data delivery and file descriptor installation. Manages context locking, remote task work, and ensures safe resource cleanup and error handling for inter-ring communication.


## napi.c
Implements NAPI (New API) busy-polling integration for io_uring, enabling efficient polling of network receive queues within the io_uring context. Manages NAPI ID registration, tracking, and removal, supports both static and dynamic tracking modes, and provides mechanisms for busy-poll loop execution, timeout handling, and cleanup of stale entries. Integrates with io_uring's wait queues to optimize network I/O latency and responsiveness.


## net.c
Implements network-related operations for io_uring, including asynchronous send, receive, accept, connect, bind, listen, and socket creation. Handles preparation and execution of network syscalls, manages message headers and buffer selection, supports multishot and zero-copy modes, and integrates with io_uring's completion and notification mechanisms for efficient non-blocking network I/O.


## nop.c
Implements the no-operation (NOP) command for io_uring, providing a lightweight request that can be used for testing, benchmarking, or as a placeholder in submission queues. Handles preparation and execution of NOP requests, supports optional result injection, file and buffer association, and integrates with io_uring's completion and error handling mechanisms.


## notif.c

## opdef.c
## openclose.c
## poll.c
## register.c
## rsrc.c
## rw.c
## splice.c
## sqpoll.c
## statx.c

## sync.c
## tctx.c
## timeout.c
## truncate.c
## uring_cmd.c
## waitid.c
## xattr.c
## zcrx.c


## How many internal headers are listed

there are 37 headers :
## advise.h
## alloc_chace.h
## cancel.h
## epol.h
## eventfd.h
## fdinfo.h
## filetable.h
## fs.h
## futex.h
## io-wq.h



## sync.h
int io_sfr_prep(struct io_kiocb *req, const struct io_uring_sqe *sqe);
int io_sync_file_range(struct io_kiocb *req, unsigned int issue_flags);

int io_fsync_prep(struct io_kiocb *req, const struct io_uring_sqe *sqe);
int io_fsync(struct io_kiocb *req, unsigned int issue_flags);

int io_fallocate(struct io_kiocb *req, unsigned int issue_flags);
int io_fallocate_prep(struct io_kiocb *req, const struct io_uring_sqe *sqe);

## tctx.h
int io_uring_alloc_task_context(struct task_struct *task,
				struct io_ring_ctx *ctx);
void io_uring_del_tctx_node(unsigned long index);
int __io_uring_add_tctx_node(struct io_ring_ctx *ctx);
int __io_uring_add_tctx_node_from_submit(struct io_ring_ctx *ctx);
void io_uring_clean_tctx(struct io_uring_task *tctx);

void io_uring_unreg_ringfd(void);
int io_ringfd_register(struct io_ring_ctx *ctx, void __user *__arg,
		       unsigned nr_args);
int io_ringfd_unregister(struct io_ring_ctx *ctx, void __user *__arg,
			 unsigned nr_args);

static inline int io_uring_add_tctx_node(struct io_ring_ctx *ctx)
{
	struct io_uring_task *tctx = current->io_uring;

	if (likely(tctx && tctx->last == ctx))
		return 0;

	return __io_uring_add_tctx_node_from_submit(ctx);
}


## timeout.h
static inline struct io_kiocb *io_disarm_linked_timeout(struct io_kiocb *req)
{
	struct io_kiocb *link = req->link;

	if (link && link->opcode == IORING_OP_LINK_TIMEOUT)
		return __io_disarm_linked_timeout(req, link);

	return NULL;
}
__cold void io_flush_timeouts(struct io_ring_ctx *ctx);
int io_timeout_cancel(struct io_ring_ctx *ctx, struct io_cancel_data *cd);
__cold bool io_kill_timeouts(struct io_ring_ctx *ctx, struct io_uring_task *tctx,
			     bool cancel_all);
void io_queue_linked_timeout(struct io_kiocb *req);
void io_disarm_next(struct io_kiocb *req);

int io_timeout_prep(struct io_kiocb *req, const struct io_uring_sqe *sqe);
int io_link_timeout_prep(struct io_kiocb *req, const struct io_uring_sqe *sqe);
int io_timeout(struct io_kiocb *req, unsigned int issue_flags);
int io_timeout_remove_prep(struct io_kiocb *req, const struct io_uring_sqe *sqe);
int io_timeout_remove(struct io_kiocb *req, unsigned int issue_flags);

## truncate.h
int io_ftruncate_prep(struct io_kiocb *req, const struct io_uring_sqe *sqe);
int io_ftruncate(struct io_kiocb *req, unsigned int issue_flags);

## uring_cmd.h
int io_uring_cmd(struct io_kiocb *req, unsigned int issue_flags);
int io_uring_cmd_prep(struct io_kiocb *req, const struct io_uring_sqe *sqe);
void io_uring_cmd_cleanup(struct io_kiocb *req);

bool io_uring_try_cancel_uring_cmd(struct io_ring_ctx *ctx,
				   struct io_uring_task *tctx, bool cancel_all);

void io_cmd_cache_free(const void *entry);

int io_uring_cmd_import_fixed_vec(struct io_uring_cmd *ioucmd,
				  const struct iovec __user *uvec,
				  size_t uvec_segs,
				  int ddir, struct iov_iter *iter,
				  unsigned issue_flags);

## waitid.h
int io_waitid_prep(struct io_kiocb *req, const struct io_uring_sqe *sqe);
int io_waitid(struct io_kiocb *req, unsigned int issue_flags);
int io_waitid_cancel(struct io_ring_ctx *ctx, struct io_cancel_data *cd,
		     unsigned int issue_flags);
bool io_waitid_remove_all(struct io_ring_ctx *ctx, struct io_uring_task *tctx,
			  bool cancel_all);

## xattr.h
void io_xattr_cleanup(struct io_kiocb *req);

int io_fsetxattr_prep(struct io_kiocb *req, const struct io_uring_sqe *sqe);
int io_fsetxattr(struct io_kiocb *req, unsigned int issue_flags);

int io_setxattr_prep(struct io_kiocb *req, const struct io_uring_sqe *sqe);
int io_setxattr(struct io_kiocb *req, unsigned int issue_flags);

int io_fgetxattr_prep(struct io_kiocb *req, const struct io_uring_sqe *sqe);
int io_fgetxattr(struct io_kiocb *req, unsigned int issue_flags);

int io_getxattr_prep(struct io_kiocb *req, const struct io_uring_sqe *sqe);
int io_getxattr(struct io_kiocb *req, unsigned int issue_flags);

## zcrx.h
#if defined(CONFIG_IO_URING_ZCRX)
int io_register_zcrx_ifq(struct io_ring_ctx *ctx,
			 struct io_uring_zcrx_ifq_reg __user *arg);
void io_unregister_zcrx_ifqs(struct io_ring_ctx *ctx);
void io_shutdown_zcrx_ifqs(struct io_ring_ctx *ctx);
int io_zcrx_recv(struct io_kiocb *req, struct io_zcrx_ifq *ifq,
		 struct socket *sock, unsigned int flags,
		 unsigned issue_flags, unsigned int *len);
#else
static inline int io_register_zcrx_ifq(struct io_ring_ctx *ctx,
					struct io_uring_zcrx_ifq_reg __user *arg)
{
	return -EOPNOTSUPP;
}
static inline void io_unregister_zcrx_ifqs(struct io_ring_ctx *ctx)
{
}
static inline void io_shutdown_zcrx_ifqs(struct io_ring_ctx *ctx)
{
}
static inline int io_zcrx_recv(struct io_kiocb *req, struct io_zcrx_ifq *ifq,
			       struct socket *sock, unsigned int flags,
			       unsigned issue_flags, unsigned int *len)
{
	return -EOPNOTSUPP;
}
#endif

int io_recvzc(struct io_kiocb *req, unsigned int issue_flags);
int io_recvzc_prep(struct io_kiocb *req, const struct io_uring_sqe *sqe);

#endif